latex
\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{geometry}

% Configuração das margens
\geometry{top=3cm, bottom=2cm, left=3cm, right=2cm}

\begin{document}

\section{Introdução}

O Problema da Mochila é um dos problemas clássicos de otimização combinatória e aparece em diversas aplicações reais, como seleção de recursos, alocação de orçamento e planejamento de carga. Na formulação adotada neste trabalho, inspirada em Carvalho (1992), considera-se o cenário de um escoteiro que precisa escolher quais itens levar em sua mochila, cada um com um peso $p_i$ e uma utilidade $u_i$, respeitando a capacidade máxima $L$. O objetivo é selecionar um subconjunto de itens que maximize a utilidade total sem ultrapassar o limite de peso.

Do ponto de vista teórico, o Problema da Mochila 0/1 é reconhecidamente difícil: sua versão de decisão é NP-Completa, o que implica que, em geral, não se espera encontrar soluções exatas eficientes para instâncias arbitrárias. Essa característica motiva a análise de diferentes abordagens, tanto exatas quanto aproximadas, cada uma com vantagens e limitações específicas.

Neste trabalho, investigamos o problema sob múltiplas perspectivas. Primeiramente, apresentamos uma justificativa formal da NP-completude do problema. Em seguida, implementamos um algoritmo exato com uso de espaço linear e analisamos suas limitações práticas. Também desenvolvemos a solução clássica por programação dinâmica, incluindo o processo de reconstrução dos itens selecionados. Por fim, propomos um algoritmo aproximado baseado em heurística gulosa, avaliando sua qualidade em relação à solução ótima e discutindo sua eficiência.

A combinação dessas técnicas permite compreender não apenas os fundamentos teóricos do Problema da Mochila, mas também o comportamento das soluções na prática, especialmente quando comparadas sob diferentes tamanhos de entrada e estratégias de resolução.

\section{Questão A}
\subsection{NP-completude do Problema da Mochila 0/1 (versão de decisão)}

Dado um conjunto de $n$ itens $C_n=\{1,\dots,n\}$, com pesos $p_i\in\mathbb{Z}_{>0}$ e utilidades $u_i\in\mathbb{Z}_{>0}$ para cada $i$, além de inteiros $L$ (capacidade) e $U$ (valor alvo), decidir se existe um subconjunto $S\subseteq C_n$ tal que
\[
\sum_{i\in S} p_i \le L
\qquad\text{e}\qquad
\sum_{i\in S} u_i \ge U.
\]

\subsubsection{A Mochila está em NP?}
Uma instância candidata é um subconjunto $S\subseteq C_n$. Dado $S$ podemos verificar em tempo polinomial se
$\sum_{i\in S} p_i\le L$ e $\sum_{i\in S} u_i\ge U$ computando as somas em $O(n)$ operações aritméticas. Logo, a versão de decisão pertence a NP.

\subsubsection{A Mochila é NP-difícil (redução de SUBSET-SUM).}
Recordemos o problema \textsc{Subset-Sum}: dada uma multiconjunto de inteiros positivos $A=\{a_1,\dots,a_n\}$ e um inteiro alvo $T$, decidir se existe $A'\subseteq A$ tal que $\sum_{a\in A'} a = T$. \textsc{Subset-Sum} é conhecido NP-completo.

Construímos, em tempo polinomial, a transformação de uma instância arbitrária $(A,T)$ de \textsc{Subset-Sum} para uma instância da Mochila 0/1 (decisão) da seguinte forma:
\begin{itemize}
  \item para cada $a_i\in A$ criamos um item $i$ com peso $p_i := a_i$ e utilidade $u_i := a_i$;
  \item escolhemos $L := T$ e $U := T$.
\end{itemize}
Assim obtemos uma instância da Mochila.

\subsubsection{Correção da redução.}
\begin{itemize}
  \item Se existe um subconjunto $A'\subseteq A$ com $\sum_{a\in A'} a = T$, então, tomando $S$ correspondente aos itens cujos pesos/utilidades são os elementos de $A'$, tem-se
    \[
    \sum_{i\in S} p_i = \sum_{a\in A'} a = T = L
    \quad\text{e}\quad
    \sum_{i\in S} u_i = \sum_{a\in A'} a = T = U,
    \]
    logo $S$ é uma solução válida para a instância da Mochila.
  \item Reciprocamente, se existe $S\subseteq C_n$ tal que $\sum_{i\in S} p_i \le L$ e $\sum_{i\in S} u_i \ge U$, então, pela escolha $p_i=u_i$ e $L=U=T$, tem-se
    \[
    \sum_{i\in S} p_i = \sum_{i\in S} u_i \quad\text{e}\quad
    \sum_{i\in S} u_i \ge T.
    \]
    Como também $\sum_{i\in S} p_i \le T$, segue que $\sum_{i\in S} p_i = T$, isto é, os elementos correspondentes a $S$ formam uma solução de \textsc{Subset-Sum}.
\end{itemize}

Portanto a transformação é correta e computável em tempo polinomial, o que demonstra que \textsc{Subset-Sum} $\le_p$ Mochila (decisão). Assim, a Mochila é NP-difícil.

A versão de decisão do Problema da Mochila 0/1 pertence a NP e é NP-difícil; logo é NP-Completa. \hfill\(\square\)

\section{Questão B}
\subsection{Implementação ingênua recursiva}
O código a seguir é a implementação ingênua recursiva, localizado no arquivo \texttt{1\_brutalF.py}:
\begin{verbatim}
#[Naive Approach] Using Recursion O(2^n) Time and O(n) Space
# Returns the maximum value that
# can be put in a knapsack of capacity W
def knapsackRec(W, val, wt, n):

  # Base Case
  if n == 0 or W == 0:
    return 0

  pick = 0

  # Pick nth item if it does not exceed the capacity of knapsack
  if wt[n - 1] <= W:
    pick = val[n - 1] + knapsackRec(W - wt[n - 1], val, wt, n - 1)

  # Don't pick the nth item
  notPick = knapsackRec(W, val, wt, n - 1)

  return max(pick, notPick)

def knapsack(W, val, wt):
  n = len(val)
  return knapsackRec(W, val, wt, n)

if __name__ == "__main__":
  val = [1, 2, 3]
  wt = [4, 5, 1]
  W = 4

  print(knapsack(W, val, wt))
\end{verbatim}

\begin{figure}[h]
\centering
% \includegraphics[width=0.75\textwidth]{figuras/impl1_times.png} % Comentei para compilar sem a imagem
\caption{Tempos medidos (escala log) para a implementação ingênua em função de $n$.}
\label{fig:impl1_times}
\end{figure}

\subsection{Maior problema com solução ótima obtida}

Experimentalmente, a maior instância para a qual foi possível obter a solução ótima utilizando uma implementação prática foi:

\begin{itemize}
    \item \textbf{Versão otimizada} (arquivo \texttt{4\_pd\_com\_itens.py}): $n = 32$, capacidade $W = 100$,
    com tempo medido $T(32) \approx 9.995\times10^{-4}\,$s (conforme registro em \texttt{results.csv}).
\end{itemize}

A implementação em \texttt{4\_pd\_com\_itens.py} (programação dinâmica com reconstrução da solução) conseguiu resolver todas as instâncias até $n=32$ sem dificuldades.

Por outro lado, a implementação ingênua (arquivo \texttt{1\_brutalF.py}) apresentou tempos aceitáveis apenas para instâncias pequenas: os experimentos mostram que, a partir de aproximadamente $n \ge 20$, o método recursivo força-bruta se torna impraticável, gerando tempo de execução excessivo ou mesmo \emph{timeout} para $n = 28, 30$ e $32$ em diversas execuções.

Esses resultados são coerentes com a complexidade exponencial da abordagem ingênua, em contraste com a solução de programação dinâmica, cujo custo é polinomial em $nW$ e portanto viável para capacidades moderadas como as testadas.


\subsection{Comentário sobre a limitação}
O comportamento observado é consistente com a análise teórica:
\begin{itemize}
    \item A implementação ingênua (arquivo \texttt{1\_brutalF.py}) tem complexidade temporal $\Theta(2^{n})$ — o número de chamadas recursivas cresce exponencialmente.
    \item A implementação por programação dinâmica (arquivo \texttt{4\_pd\_com\_itens.py}) tem custo polinomial dependente de $n$ e da capacidade $W$, resultando em tempos muito menores na prática quando $W$ é moderado.
\end{itemize}

Na prática, cada incremento em $n$ tende a multiplicar o tempo por fator próximo de 2 na versão ingênua, daí o crescimento exponencial observado.

\subsection{Estimativa para entrada 10x maior que o maior problema resolvido}
Vamos estimar o tempo necessário para uma entrada $10\times$ maior que o maior problema resolvido experimentalmente ($n_{max}=32$). Mostramos duas estimativas: para a implementação exata (arquivo \texttt{4\_pd\_com\_itens.py}) e para a implementação ingênua (arquivo \texttt{1\_brutalF.py}) usando o ajuste exponencial obtido dos dados.

\subsubsection{Implementação exata (hipótese A: $W$ fixo)}

Se a capacidade $W$ permanece aproximadamente constante, o tempo da
implementação por programação dinâmica cresce de forma aproximadamente linear
em relação a $n$. Assim, para $n' = 10 \times 32 = 320$:

\[
T(320)
    \approx T(32)\cdot \frac{320}{32}
    \approx 9.995\times 10^{-4} \cdot 10
    \approx 9.995\times 10^{-3}\ \text{s}
    \approx 0.01\ \text{s}.
\]



\subsubsection{Implementação exata (hipótese B: $W$ cresce 10$\times$)}

Se tanto $n$ quanto a capacidade $W$ aumentarem por um fator $10$, o custo
total (proporcional a $nW$) cresce aproximadamente por um fator $100$. Assim:

\[
T(320, W' = 10W)
    \approx 100 \times T(32)
    \approx 100 \times 9.995\times 10^{-4}
    \approx 9.995\times 10^{-2}\ \text{s}
    \approx 0.10\ \text{s}.
\]


\subsubsection{Implementação ingênua — extrapolação exponencial}

Ajustando um modelo exponencial \(T(n) \approx a\, b^{n}\) aos tempos medidos para a implementação ingênua, obteve-se (via regressão linear em \(\ln T\)):

\[
\begin{aligned}
a &\approx 4.9621 \times 10^{-7},\\
b &\approx 1.99023.
\end{aligned}
\]

Usando esse modelo para \(n' = 320\) (isto é, \(10 \times 32\)), temos:

\[
\begin{aligned}
T_{\text{naive}}(320)
&\approx a \cdot b^{320} \\
&\approx 2.211 \times 10^{89}\ \text{segundos} \\
&\approx 7.01 \times 10^{81}\ \text{anos}.
\end{aligned}
\]

A extrapolação confirma que a versão ingênua é completamente impraticável para entradas maiores. Em contraste, a implementação por programação dinâmica permanece viável sob hipóteses razoáveis sobre o valor máximo da capacidade \(W\).


\section{Questão C}

\subsubsection{Implementação em Python (arquivo \texttt{4\_pd\_com\_itens.py})}

A seguir apresenta-se a implementação do algoritmo de programação dinâmica
para o problema da mochila 0/1, incluindo o procedimento completo de
reconstrução dos itens que compõem a solução ótima.

\begin{verbatim}
"""
Dynamic programming 0/1 knapsack with item reconstruction.

Provides two functions:
- `knapsack(W, val, wt)` -> returns maximum total value (int)
(keeps compatibility)
- `knapsack_with_items(W, val, wt)` -> returns (total_value,
chosen_indices)

When run as a script, demonstrates the algorithm and prints which items were
chosen (by index) and the total value.
"""
# algoritmio 2 mas mostrando os itens selecionados
def knapsack_with_items(W, val, wt):
  """
  Bottom-up DP for 0/1 knapsack that also reconstructs the chosen
  items.

  Returns a tuple (max_value, chosen_indices) where chosen_indices
  is a list of item indices (0-based) that were selected to achieve
  max_value. The reconstruction prefers higher-index items first when
  ties occur because of
  the backtracking order.
  """
  n = len(val)
  # dp[i][w] = max value using first i items (items 0..i-1) with
  # capacity w
  dp = [[0] * (W + 1) for _ in range(n + 1)]

  for i in range(1, n + 1):
    vi = val[i - 1]
    wi = wt[i - 1]
    for w in range(0, W + 1):
      if wi <= w:
        # pick or not pick
        pick = vi + dp[i - 1][w - wi]
        not_pick = dp[i - 1][w]
        dp[i][w] = max(pick, not_pick)
      else:
        dp[i][w] = dp[i - 1][w]

  # Reconstruct chosen items
  chosen = []
  w = W
  for i in range(n, 0, -1):
    if dp[i][w] != dp[i - 1][w]:
      # item i-1 was taken
      chosen.append(i - 1)
      w -= wt[i - 1]
      if w <= 0:
        break

  chosen.reverse()
  return dp[n][W], chosen


def knapsack(W, val, wt):
  """Compatibility wrapper that returns only the max value (int)."""
  max_val, _ = knapsack_with_items(W, val, wt)
  return max_val


if __name__ == '__main__':
  # Demo example
  val = [1, 2, 3]
  wt = [4, 5, 1]
  W = 4

  total, items = knapsack_with_items(W, val, wt)
  print(f"Max value: {total}")
  print(f"Chosen item indices: {items}")
\end{verbatim}

\subsection{Origem e referência}
Parte da explicação e do exemplo foi consultada no tutorial do W3Schools
relacionado ao problema da mochila.
\textbf{Referência}:
W3Schools — ``Knapsack Problem''. Disponível em:
\url{https://www.w3schools.com/dsa/dsa_ref_knapsack.php}. Acessado como material de apoio.

\subsection{Imagem do tutorial}

A Figura~\ref{fig:tabela_w3} mostra a tabela de programação dinâmica apresentada
no tutorial, utilizada para ilustrar o processo de reconstrução dos itens.

\begin{figure}[h]
\centering
% \includegraphics[width=0.7\textwidth]{figuras/tabela.png} % Comentei para compilar sem a imagem
\caption{Tabela de DP usada na reconstrução dos itens (fonte: W3Schools).}
\label{fig:tabela_w3}
\end{figure}

\section{Questão D}

Usamos uma heurística gulosa baseada na razão valor/peso. Ordena-se os itens por $v/w$ decrescente e seleciona-se enquanto houver capacidade. Complexidade: $O(n\log n)$ pela ordenação.

\subsection{Código (arquivo \texttt{3\_greed.py})}
\begin{verbatim}
#[Approximation] Greedy approach (value/weight ratio) - O(n log n) time
def knapsack(W, val, wt):
  """
  Greedy approximation for 0/1 knapsack: sort items by value/weight
  ratio and pick while capacity allows. This is not optimal in general
  but is fast and useful for large instances.

  Returns the total value of the chosen items.
  """
  n = len(val)
  items = []
  for i in range(n):
    if wt[i] <= 0:
      # avoid division by zero; treat zero-weight items as very high ratio
      ratio = float('inf')
    else:
      ratio = val[i] / wt[i]
    items.append((ratio, wt[i], val[i], i))

  # Sort by descending ratio
  items.sort(key=lambda x: x[0], reverse=True)

  remaining = W
  total_value = 0
  chosen = []
  for ratio, w, v, idx in items:
    if w <= remaining:
      chosen.append(idx)
      remaining -= w
      total_value += v
    # can't pick more if capacity is exhausted
    if remaining == 0:
      break

  return total_value

if __name__ == "__main__":
  val = [1, 2, 3]
  wt = [4, 5, 1]
  W = 4

  print(knapsack(W, val, wt))
\end{verbatim}

\subsection{Observações práticas}
- A heurística é extremamente rápida e serve como baseline para instâncias grandes.
- Em vários casos práticos produz soluções próximas do ótimo; entretanto, existem instâncias em que a heurística falha (ex.: itens com baixos pesos e altos valores combinados que não são capturados pela simples razão).

\section{Questão E}
Esta seção apresenta a análise assintótica das implementações desenvolvidas, considerando tempo e espaço.

\subsection{Algoritmo 1 — \texttt{1\_brutalF.py} (ingênuo recursivo)}
A implementação ingênua explora o espaço de soluções através de uma árvore de recursão.
\begin{itemize}
  \item \textbf{Tempo:} $\Theta(2^{n})$. No pior caso, para cada item, há duas decisões (pegar ou não), gerando uma árvore binária completa de altura $n$.
  \item \textbf{Espaço:} $O(n)$. O consumo de memória é dominado pela pilha de chamadas recursivas, que atinge profundidade $n$.
\end{itemize}

\subsection{Algoritmo 2 — \texttt{2\_pd.py} e \texttt{4\_pd\_com\_itens.py} (Programação Dinâmica)}
As soluções baseadas em Programação Dinâmica (tanto top-down quanto bottom-up) evitam recomputações armazenando resultados de subproblemas.
\begin{itemize}
  \item \textbf{Tempo:} $O(nW)$. O algoritmo preenche uma tabela de tamanho $(n+1) \times (W+1)$, onde cada célula é calculada em tempo constante $O(1)$.
  \item \textbf{Espaço:} $O(nW)$. Necessário para manter a tabela de estados. (Nota: em \texttt{4\_pd\_com\_itens.py}, a tabela completa é mantida para permitir a reconstrução da solução; se apenas o valor fosse necessário, o espaço poderia ser reduzido para $O(W)$).
\end{itemize}

\subsection{Algoritmo 3 — \texttt{3\_greed.py} (Heurística Gulosa)}
A heurística ordena os itens pela razão valor/peso e os seleciona iterativamente.
\begin{itemize}
  \item \textbf{Tempo:} $O(n\log n)$. A complexidade é dominada pelo algoritmo de ordenação ($O(n\log n)$). A seleção subsequente é linear $O(n)$.
  \item \textbf{Espaço:} $O(n)$. Necessário para armazenar a lista de itens e estruturas auxiliares da ordenação.
\end{itemize}

\subsection{Resumo Comparativo}
A tabela a seguir resume as ordens de complexidade:

\begin{table}[h]
\centering
\begin{tabular}{@{}llcc@{}}
\toprule
Algoritmo & Método & Tempo & Espaço \\
\midrule
\texttt{1\_brutalF.py} & Força Bruta & $\Theta(2^n)$ & $O(n)$ \\
\texttt{2\_pd.py} & Prog. Dinâmica & $O(nW)$ & $O(nW)$ \\
\texttt{3\_greed.py} & Guloso & $O(n\log n)$ & $O(n)$ \\
\bottomrule
\end{tabular}
\caption{Comparação de complexidade teórica.}
\end{table}

\noindent \textbf{Conclusão:} A heurística gulosa é a mais eficiente em tempo ($O(n\log n)$), mas não garante otimalidade. A PD é pseudo-polinomial ($O(nW)$), sendo eficiente para capacidades $W$ moderadas. A força bruta é exponencial e inviável para $n$ grande.

\section{Questão F}

Nesta seção avaliamos o quão próxima a heurística gulosa (arquivo \texttt{3\_greed.py}) chega da solução ótima obtida pela implementação baseada em programação dinâmica (arquivo \texttt{4\_pd\_com\_itens.py}). A análise utiliza os valores armazenados em \texttt{results.csv}. Para cada par (capacidade $W$, número de itens $n$) em que ambos os algoritmos retornaram uma resposta com status \texttt{ok}, calculamos:

\begin{itemize}
  \item \textbf{Diferença absoluta:} $\Delta = V_{opt} - V_{approx}$;
  \item \textbf{Diferença relativa (\%):} $100 \times (V_{opt} - V_{approx})/V_{opt}$.
\end{itemize}

\subsection{Tabela de comparações}

\begin{table}[h]
\centering
\begin{tabular}{@{}rrr r r r@{}}
\toprule
 $W$ & $n$ & $V_{opt}$ & $V_{approx}$ & $\Delta$ & gap (\%) \\
\midrule
 13  & 5  & 43   & 35   & 8  & 18.60 \\
 40  & 10 & 488  & 488  & 0  & 0.00 \\
 70  & 20 & 879  & 868  & 11 & 1.25 \\
 100 & 28 & 1290 & 1283 & 7  & 0.54 \\
 100 & 30 & 1327 & 1327 & 0  & 0.00 \\
 100 & 32 & 1428 & 1421 & 7  & 0.49 \\
\bottomrule
\end{tabular}
\caption{Comparação entre valor ótimo ($V_{opt}$) e valor obtido pela heurística gulosa ($V_{approx}$). O gap representa a diferença relativa em relação ao valor ótimo.}
\end{table}

\subsubsection{Estatísticas sumarizadas}

Com base nos 6 cenários comparáveis, obtemos:

\begin{itemize}
  \item \textbf{Média do gap relativo:} $\approx 3.48\%$;
  \item \textbf{Mediana do gap relativo:} $\approx 0.52\%$;
  \item \textbf{Máximo gap relativo:} $18.60\%$ (caso $W=13$, $n=5$).
\end{itemize}

\section{Questão G}

\subsection{Metodologia}

Os testes aleatórios foram conduzidos pelo script \texttt{scripts/random\_tests.py}. Para cada valor de
$n \in \{8, 12, 16, 20, 24\}$ foram geradas $5$ instâncias independentes, com pesos inteiros sorteados
uniformemente em $[1,20]$ e valores inteiros em $[1,100]$. A capacidade da mochila seguiu a convenção
\[
W = \left\lfloor \frac{\sum_i w_i}{2} \right\rfloor,
\]
o que garante instâncias de dificuldade moderada (nem triviais, nem saturadas).

Para cada instância, executaram-se as quatro implementações (impl\_1, impl\_2, impl\_3, impl\_4),
registrando-se tanto o tempo de execução quanto o valor final obtido por cada método.
Os resultados brutos encontram-se em \texttt{scripts/random\_results.csv}.


\subsection{Resultados (médias)}

A Tabela~\ref{tab:resultados-medios} apresenta os tempos médios de execução (em segundos) das quatro
implementações testadas, juntamente com o \emph{gap} médio entre a solução ótima (obtida pela
implementação por programação dinâmica com reconstrução, \texttt{impl\_4}) e a heurística gulosa
(\texttt{impl\_3}). Os valores foram extraídos diretamente do sumário gerado pelo script de testes.

\begin{table}[h]
\centering
\begin{tabular}{rrrrrr}
\toprule
$n$ & impl\_1 (s) & impl\_2 (s) & impl\_3 (s) & impl\_4 (s) & avg gap \\
\midrule
 8  & 0.0001 & 0.0001 & 0.0000 & 0.0001 & 6.40 \\
 12 & 0.0015 & 0.0002 & 0.0000 & 0.0003 & 12.20 \\
 16 & 0.0202 & 0.0003 & 0.0000 & 0.0004 & 6.60 \\
 20 & 0.3227 & 0.0005 & 0.0000 & 0.0006 & 10.00 \\
 24 & 5.1303 & 0.0009 & 0.0000 & 0.0010 & 4.00 \\
\bottomrule
\end{tabular}
\caption{Tempos médios de execução (em segundos) e \emph{gap} médio entre o valor ótimo (impl\_4)
e o valor aproximado (impl\_3) obtidos em instâncias aleatórias.}
\label{tab:resultados-medios}
\end{table}


\subsection{Contagem de Operações (Experimental)}
A tabela abaixo mostra o número médio de operações elementares (chamadas recursivas, iterações em loops internos ou comparações principais) realizadas por cada implementação.

\begin{table}[h]
\centering
\begin{tabular}{rrrrr}
	\toprule
$n$ & impl\_1 (ops) & impl\_2 (ops) & impl\_3 (ops) & impl\_4 (ops) \\
\midrule
8  & 511   & 548    & 35   & 615 \\
12 & 8191  & 826    & 55   & 922 \\
16 & 131071 & 1104   & 77   & 1229 \\
20 & 2097151 & 1382   & 101  & 1536 \\
24 & -      & 1660   & 126  & 1843 \\
\bottomrule
\end{tabular}
\caption{Número médio de operações elementares. Nota: Para $n=24$, a força bruta (\texttt{impl\_1}) excede limites práticos e não foi contabilizada.}
\end{table}

\subsection{Discussão}
Os resultados experimentais concordam com as previsões teóricas discutidas no item anterior:
\begin{itemize}
  \item A implementação ingênua (`impl\_1`) apresenta crescimento exponencial em $n$; os tempos medidos crescem rapidamente (note o salto entre $n=20$ e $n=24$), coerente com um comportamento ~O($2^n$). O ajuste realizado previamente mostrou fator de base próximo de $1.99$, o que reforça a hipótese de complexidade exponencial.
  \item A programação dinâmica exata (`impl\_4`) tem complexidade teórica O($nW$). Nas instâncias geradas $W$ é proporcional à soma dos pesos e, portanto, cresce com $n$; ainda assim, os tempos observados permanecem baixos para os valores de $n$ testados graças às constantes de implementação e aos limites modestos de $W$ usados nos testes.
  \item A heurística gulosa (`impl\_3`) tem custo dominante de ordenação O($n\log n$) e comportamento prático muito rápido. Nos testes, a heurística frequentemente produziu soluções muito próximas do ótimo (gaps médios baixos), embora de forma não garantida -- há casos patológicos em que a heurística falha.
\end{itemize}

Em resumo, os testes aleatórios confirmam que a análise teórica é um bom indicador do comportamento prático: a implementação ingênua é impraticável para $n$ moderadamente grandes; a PD oferece exatidão com custo dependente de $W$; a heurística é rápida e, na prática, costuma entregar soluções de boa qualidade.

\subsection{Listagens e descrições detalhadas dos algoritmos}

Nesta seção, apresentamos a listagem completa e uma análise detalhada das estruturas de dados e funcionamento dos algoritmos 1 (Força Bruta), 2 (Programação Dinâmica Espaço Otimizado) e 4 (Programação Dinâmica com Reconstrução), conforme solicitado.

\subsubsection{Algoritmo 1: Força Bruta Recursiva (\texttt{1\_brutalF.py})}

\textbf{Descrição do Algoritmo:}
Este algoritmo implementa a abordagem clássica de recursão. Para cada item, a função decide entre duas opções: (1) incluir o item na mochila (se couber) ou (2) não incluir. O valor retornado é o máximo entre essas duas escolhas.

\textbf{Estruturas de Dados:}
Utiliza apenas a pilha de execução (stack) para manter o estado das chamadas recursivas. Os dados de entrada são listas simples.

\textbf{Análise de Complexidade:}
Como cada item gera dois ramos na árvore de recursão, a complexidade temporal é $O(2^n)$. O espaço auxiliar é $O(n)$ devido à profundidade máxima da recursão.

\textbf{Listagem do Código:}
\begin{verbatim}
# [Abordagem Ingênua] Usando Recursão O(2^n) Tempo e O(n) Espaço
# Retorna o valor máximo que pode ser colocado em uma mochila de capacidade W
def knapsackRec(W, val, wt, n):

    # Caso Base: se não houver itens ou capacidade, o valor é 0
    if n == 0 or W == 0:
        return 0

    pick = 0

    # Escolhe o n-ésimo item se ele não exceder a capacidade da mochila
    if wt[n - 1] <= W:
        pick = val[n - 1] + knapsackRec(W - wt[n - 1], val, wt, n - 1)

    # Não escolhe o n-ésimo item
    notPick = knapsackRec(W, val, wt, n - 1)

    # Retorna o máximo entre escolher ou não o item
    return max(pick, notPick)

def knapsack(W, val, wt):
    n = len(val)
    return knapsackRec(W, val, wt, n)
\end{verbatim}

\subsubsection*{Algoritmo 2: Programação Dinâmica Bottom-Up - Espaço Otimizado (\texttt{2\_pd.py})}

\textbf{Descrição do Algoritmo:}
Este algoritmo resolve o problema iterativamente preenchendo uma tabela de programação dinâmica. A otimização chave aqui é o uso de um array unidimensional \texttt{dp} de tamanho $W+1$. Ao iterar sobre os pesos de trás para frente (de $W$ até o peso do item atual), garantimos que estamos usando os valores da iteração anterior (ou seja, sem o item atual) para calcular o novo máximo, evitando o uso múltiplo do mesmo item (problema da mochila 0/1).

\textbf{Estruturas de Dados:}
Utiliza um vetor unidimensional (lista em Python) de tamanho $W+1$.

\textbf{Análise de Complexidade:}
Tempo: $O(nW)$, pois percorremos a capacidade $W$ para cada um dos $n$ itens. Espaço: $O(W)$, reduzindo significativamente o consumo de memória em comparação com a tabela 2D completa.

\textbf{Listagem do Código:}
\begin{verbatim}
# [Abordagem Esperada] Usando PD Bottom-Up (Espaço Otimizado) - O(n x W) Tempo e O(W) Espaço
# Função para encontrar o lucro máximo
def knapsack(W, val, wt):

    # Inicializando a lista dp com 0
    # dp[j] armazenará o valor máximo para a capacidade j
    dp = [0] * (W + 1)

    # Considerando os itens um por um
    for i in range(1, len(wt) + 1):

        # Percorrendo de trás para frente (de W até o peso do item atual)
        # Isso garante que estamos usando os dados da computação anterior (i-1 itens)
        # sem reutilizar o mesmo item na mesma iteração
        for j in range(W, wt[i - 1] - 1, -1):
            dp[j] = max(dp[j], dp[j - wt[i - 1]] + val[i - 1])

    return dp[W]
\end{verbatim}

\subsubsection{Algoritmo 4: Programação Dinâmica com Reconstrução (\texttt{4\_pd\_com\_itens.py})}

\textbf{Descrição do Algoritmo:}
Diferente do Algoritmo 2, esta versão constrói a tabela completa $DP[n+1][W+1]$. Isso é necessário para permitir o \textit{backtracking} ao final do preenchimento e descobrir quais itens compõem a solução ótima. O algoritmo preenche a tabela baseando-se na recorrência clássica: $DP[i][w] = \max(DP[i-1][w], val[i] + DP[i-1][w-wt[i]])$.

\textbf{Estruturas de Dados:}
Matriz bidimensional de tamanho $(n+1) \times (W+1)$.

\textbf{Análise de Complexidade:}
Tempo: $O(nW)$. Espaço: $O(nW)$. Embora consuma mais memória que o Algoritmo 2, é essencial para quando a lista de itens escolhidos é requerida, não apenas o valor máximo.

\textbf{Listagem do Código:}
\begin{verbatim}
def knapsack_with_items(W, val, wt):
	"""
	PD Bottom-up para mochila 0/1 que também reconstrói os itens escolhidos.

	Retorna uma tupla (max_value, chosen_indices) onde chosen_indices é uma lista
	de índices de itens (base 0) que foram selecionados para alcançar o max_value.
    A reconstrução prefere itens de índice mais alto primeiro quando ocorrem empates
    devido à ordem de backtracking.
	"""
	n = len(val)
	# dp[i][w] = valor máximo usando os primeiros i itens (itens 0..i-1) com capacidade w
	dp = [[0] * (W + 1) for _ in range(n + 1)]

	for i in range(1, n + 1):
		vi = val[i - 1]
		wi = wt[i - 1]
		for w in range(0, W + 1):
			if wi <= w:
				# escolher ou não escolher
				pick = vi + dp[i - 1][w - wi]
				not_pick = dp[i - 1][w]
				dp[i][w] = max(pick, not_pick)
			else:
				# não pode escolher pois excede a capacidade atual
				dp[i][w] = dp[i - 1][w]

	# Reconstruir itens escolhidos (Backtracking na tabela DP)
	chosen = []
	w = W
	for i in range(n, 0, -1):
		if dp[i][w] != dp[i - 1][w]:
			# o item i-1 foi pego
			chosen.append(i - 1)
			w -= wt[i - 1]
			if w <= 0:
				break

	chosen.reverse()
	return dp[n][W], chosen
\end{verbatim}


\section{Conclusão Final}
Em resumo, este estudo comparou três abordagens clássicas para o Problema da Mochila:

\begin{itemize}
  \item \textbf{Força Bruta (\texttt{1\_brutalF.py})}: Garante a solução ótima, mas seu custo exponencial a torna impraticável para $n > 25$.
  \item \textbf{Programação Dinâmica (\texttt{4\_pd\_com\_itens.py})}: Garante a solução ótima e é muito eficiente para capacidades $W$ moderadas, com complexidade $O(nW)$.
  \item \textbf{Heurística Gulosa (\texttt{3\_greed.py})}: Extremamente rápida ($O(n\log n)$), ideal para instâncias massivas, embora não garanta otimalidade (erro médio de $\approx 3.5\%$ nos testes).
\end{itemize}

Recomenda-se o uso da abordagem gulosa para decisões rápidas em grandes volumes de dados e a programação dinâmica quando a precisão é crítica e a capacidade permite.

\section{Referências}
\begin{itemize}
  \item W3Schools. \emph{DSA Knapsack Problem}. Disponível em: \url{https://www.w3schools.com/dsa/dsa_ref_knapsack.php}. Acesso em: 2025.
  \item GeeksforGeeks. \emph{0/1 Knapsack Problem | DP-10}. Disponível em: \url{https://www.geeksforgeeks.org/dsa/0-1-knapsack-problem-dp-10/}. Acesso em: 2025.
\end{itemize}

\end{document}
